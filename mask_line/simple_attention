digraph {
	graph [size="71.25,71.25"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2808907868160 [label="
 (1, 3, 240, 320)" fillcolor=darkolivegreen1]
	2808907772016 [label=ConvolutionBackward0]
	2808907607120 -> 2808907772016
	2808907607120 [label=ReluBackward0]
	2808907771824 -> 2808907607120
	2808907771824 [label=NativeBatchNormBackward0]
	2808907772208 -> 2808907771824
	2808907772208 [label=ConvolutionBackward0]
	2808907772400 -> 2808907772208
	2808907772400 [label=ReluBackward0]
	2808907772592 -> 2808907772400
	2808907772592 [label=NativeBatchNormBackward0]
	2808907772688 -> 2808907772592
	2808907772688 [label=ConvolutionBackward0]
	2808907772880 -> 2808907772688
	2808907772880 [label=CatBackward0]
	2808907773072 -> 2808907772880
	2808907773072 [label=UpsampleBilinear2DBackward0]
	2808906656944 -> 2808907773072
	2808906656944 [label=ReluBackward0]
	2808907773264 -> 2808906656944
	2808907773264 [label=NativeBatchNormBackward0]
	2808907773360 -> 2808907773264
	2808907773360 [label=ConvolutionBackward0]
	2808907773552 -> 2808907773360
	2808907773552 [label=ReluBackward0]
	2808907773744 -> 2808907773552
	2808907773744 [label=NativeBatchNormBackward0]
	2808907773840 -> 2808907773744
	2808907773840 [label=ConvolutionBackward0]
	2808907774032 -> 2808907773840
	2808907774032 [label=CatBackward0]
	2808907774224 -> 2808907774032
	2808907774224 [label=UpsampleBilinear2DBackward0]
	2808907774368 -> 2808907774224
	2808907774368 [label=ReluBackward0]
	2808907774464 -> 2808907774368
	2808907774464 [label=NativeBatchNormBackward0]
	2808907774560 -> 2808907774464
	2808907774560 [label=ConvolutionBackward0]
	2808907774752 -> 2808907774560
	2808907774752 [label=ReluBackward0]
	2808907774944 -> 2808907774752
	2808907774944 [label=NativeBatchNormBackward0]
	2808907775040 -> 2808907774944
	2808907775040 [label=ConvolutionBackward0]
	2808907775232 -> 2808907775040
	2808907775232 [label=CatBackward0]
	2808907775424 -> 2808907775232
	2808907775424 [label=UpsampleBilinear2DBackward0]
	2808907775568 -> 2808907775424
	2808907775568 [label=AddBackward0]
	2808889112272 -> 2808907775568
	2808889112272 [label=MulBackward0]
	2808907775760 -> 2808889112272
	2808907775760 [label=MaxPool2DWithIndicesBackward0]
	2808907775904 -> 2808907775760
	2808907775904 [label=ReluBackward0]
	2808907775952 -> 2808907775904
	2808907775952 [label=NativeBatchNormBackward0]
	2808908103840 -> 2808907775952
	2808908103840 [label=ConvolutionBackward0]
	2808908104032 -> 2808908103840
	2808908104032 [label=ReluBackward0]
	2808908104224 -> 2808908104032
	2808908104224 [label=NativeBatchNormBackward0]
	2808908104320 -> 2808908104224
	2808908104320 [label=ConvolutionBackward0]
	2808908104512 -> 2808908104320
	2808908104512 [label=MaxPool2DWithIndicesBackward0]
	2808908104704 -> 2808908104512
	2808908104704 [label=ReluBackward0]
	2808908104800 -> 2808908104704
	2808908104800 [label=NativeBatchNormBackward0]
	2808908104896 -> 2808908104800
	2808908104896 [label=ConvolutionBackward0]
	2808908105088 -> 2808908104896
	2808908105088 [label=ReluBackward0]
	2808908105280 -> 2808908105088
	2808908105280 [label=NativeBatchNormBackward0]
	2808908105376 -> 2808908105280
	2808908105376 [label=ConvolutionBackward0]
	2808908105568 -> 2808908105376
	2808908105568 [label=MaxPool2DWithIndicesBackward0]
	2808908105760 -> 2808908105568
	2808908105760 [label=ReluBackward0]
	2808908105856 -> 2808908105760
	2808908105856 [label=NativeBatchNormBackward0]
	2808908105952 -> 2808908105856
	2808908105952 [label=ConvolutionBackward0]
	2808908106144 -> 2808908105952
	2808908106144 [label=ReluBackward0]
	2808908106336 -> 2808908106144
	2808908106336 [label=NativeBatchNormBackward0]
	2808908106432 -> 2808908106336
	2808908106432 [label=ConvolutionBackward0]
	2808908106624 -> 2808908106432
	2808858975504 [label="rgb_encoder.blocks.0.0.weight
 (8, 3, 3, 3)" fillcolor=lightblue]
	2808858975504 -> 2808908106624
	2808908106624 [label=AccumulateGrad]
	2808908106576 -> 2808908106432
	2808858975424 [label="rgb_encoder.blocks.0.0.bias
 (8)" fillcolor=lightblue]
	2808858975424 -> 2808908106576
	2808908106576 [label=AccumulateGrad]
	2808908106384 -> 2808908106336
	2808858974704 [label="rgb_encoder.blocks.0.1.weight
 (8)" fillcolor=lightblue]
	2808858974704 -> 2808908106384
	2808908106384 [label=AccumulateGrad]
	2808908106240 -> 2808908106336
	2808858981104 [label="rgb_encoder.blocks.0.1.bias
 (8)" fillcolor=lightblue]
	2808858981104 -> 2808908106240
	2808908106240 [label=AccumulateGrad]
	2808908106096 -> 2808908105952
	2808858980464 [label="rgb_encoder.blocks.0.3.weight
 (8, 8, 3, 3)" fillcolor=lightblue]
	2808858980464 -> 2808908106096
	2808908106096 [label=AccumulateGrad]
	2808908106048 -> 2808908105952
	2808858973984 [label="rgb_encoder.blocks.0.3.bias
 (8)" fillcolor=lightblue]
	2808858973984 -> 2808908106048
	2808908106048 [label=AccumulateGrad]
	2808908105904 -> 2808908105856
	2808858973904 [label="rgb_encoder.blocks.0.4.weight
 (8)" fillcolor=lightblue]
	2808858973904 -> 2808908105904
	2808908105904 [label=AccumulateGrad]
	2808908105664 -> 2808908105856
	2808858980304 [label="rgb_encoder.blocks.0.4.bias
 (8)" fillcolor=lightblue]
	2808858980304 -> 2808908105664
	2808908105664 [label=AccumulateGrad]
	2808908105520 -> 2808908105376
	2808858973344 [label="rgb_encoder.blocks.1.0.weight
 (16, 8, 3, 3)" fillcolor=lightblue]
	2808858973344 -> 2808908105520
	2808908105520 [label=AccumulateGrad]
	2808908105472 -> 2808908105376
	2808858973264 [label="rgb_encoder.blocks.1.0.bias
 (16)" fillcolor=lightblue]
	2808858973264 -> 2808908105472
	2808908105472 [label=AccumulateGrad]
	2808908105328 -> 2808908105280
	2808858979664 [label="rgb_encoder.blocks.1.1.weight
 (16)" fillcolor=lightblue]
	2808858979664 -> 2808908105328
	2808908105328 [label=AccumulateGrad]
	2808908105184 -> 2808908105280
	2808858973184 [label="rgb_encoder.blocks.1.1.bias
 (16)" fillcolor=lightblue]
	2808858973184 -> 2808908105184
	2808908105184 [label=AccumulateGrad]
	2808908105040 -> 2808908104896
	2808858972624 [label="rgb_encoder.blocks.1.3.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	2808858972624 -> 2808908105040
	2808908105040 [label=AccumulateGrad]
	2808908104992 -> 2808908104896
	2808858979424 [label="rgb_encoder.blocks.1.3.bias
 (16)" fillcolor=lightblue]
	2808858979424 -> 2808908104992
	2808908104992 [label=AccumulateGrad]
	2808908104848 -> 2808908104800
	2808858979344 [label="rgb_encoder.blocks.1.4.weight
 (16)" fillcolor=lightblue]
	2808858979344 -> 2808908104848
	2808908104848 [label=AccumulateGrad]
	2808908104608 -> 2808908104800
	2808858972864 [label="rgb_encoder.blocks.1.4.bias
 (16)" fillcolor=lightblue]
	2808858972864 -> 2808908104608
	2808908104608 [label=AccumulateGrad]
	2808908104464 -> 2808908104320
	2808858972384 [label="rgb_encoder.blocks.2.0.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	2808858972384 -> 2808908104464
	2808908104464 [label=AccumulateGrad]
	2808908104416 -> 2808908104320
	2808858972304 [label="rgb_encoder.blocks.2.0.bias
 (32)" fillcolor=lightblue]
	2808858972304 -> 2808908104416
	2808908104416 [label=AccumulateGrad]
	2808908104272 -> 2808908104224
	2808858978704 [label="rgb_encoder.blocks.2.1.weight
 (32)" fillcolor=lightblue]
	2808858978704 -> 2808908104272
	2808908104272 [label=AccumulateGrad]
	2808908104128 -> 2808908104224
	2808858972224 [label="rgb_encoder.blocks.2.1.bias
 (32)" fillcolor=lightblue]
	2808858972224 -> 2808908104128
	2808908104128 [label=AccumulateGrad]
	2808908103984 -> 2808908103840
	2808858978144 [label="rgb_encoder.blocks.2.3.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	2808858978144 -> 2808908103984
	2808908103984 [label=AccumulateGrad]
	2808908103936 -> 2808908103840
	2808858978064 [label="rgb_encoder.blocks.2.3.bias
 (32)" fillcolor=lightblue]
	2808858978064 -> 2808908103936
	2808908103936 [label=AccumulateGrad]
	2808908103792 -> 2808907775952
	2808858971584 [label="rgb_encoder.blocks.2.4.weight
 (32)" fillcolor=lightblue]
	2808858971584 -> 2808908103792
	2808908103792 [label=AccumulateGrad]
	2808908103744 -> 2808907775952
	2808858971504 [label="rgb_encoder.blocks.2.4.bias
 (32)" fillcolor=lightblue]
	2808858971504 -> 2808908103744
	2808908103744 [label=AccumulateGrad]
	2808907775712 -> 2808889112272
	2808907775712 [label=SigmoidBackward0]
	2808907775808 -> 2808907775712
	2808907775808 [label=ConvolutionBackward0]
	2808908104176 -> 2808907775808
	2808908104176 [label=ReluBackward0]
	2808908104560 -> 2808908104176
	2808908104560 [label=ConvolutionBackward0]
	2808908105424 -> 2808908104560
	2808908105424 [label=CatBackward0]
	2808907775760 -> 2808908105424
	2808907775664 -> 2808908105424
	2808907775664 [label=MaxPool2DWithIndicesBackward0]
	2808908105616 -> 2808907775664
	2808908105616 [label=ReluBackward0]
	2808908106288 -> 2808908105616
	2808908106288 [label=NativeBatchNormBackward0]
	2808908106192 -> 2808908106288
	2808908106192 [label=ConvolutionBackward0]
	2808908106720 -> 2808908106192
	2808908106720 [label=ReluBackward0]
	2808908106960 -> 2808908106720
	2808908106960 [label=NativeBatchNormBackward0]
	2808908107056 -> 2808908106960
	2808908107056 [label=ConvolutionBackward0]
	2808908107248 -> 2808908107056
	2808908107248 [label=MaxPool2DWithIndicesBackward0]
	2808908107440 -> 2808908107248
	2808908107440 [label=ReluBackward0]
	2808908107536 -> 2808908107440
	2808908107536 [label=NativeBatchNormBackward0]
	2808908107632 -> 2808908107536
	2808908107632 [label=ConvolutionBackward0]
	2808908107824 -> 2808908107632
	2808908107824 [label=ReluBackward0]
	2808908108016 -> 2808908107824
	2808908108016 [label=NativeBatchNormBackward0]
	2808908108112 -> 2808908108016
	2808908108112 [label=ConvolutionBackward0]
	2808908108304 -> 2808908108112
	2808908108304 [label=MaxPool2DWithIndicesBackward0]
	2808908108496 -> 2808908108304
	2808908108496 [label=ReluBackward0]
	2808908108592 -> 2808908108496
	2808908108592 [label=NativeBatchNormBackward0]
	2808908108688 -> 2808908108592
	2808908108688 [label=ConvolutionBackward0]
	2808908108880 -> 2808908108688
	2808908108880 [label=ReluBackward0]
	2808908109072 -> 2808908108880
	2808908109072 [label=NativeBatchNormBackward0]
	2808908109168 -> 2808908109072
	2808908109168 [label=ConvolutionBackward0]
	2808908109360 -> 2808908109168
	2808858984384 [label="depth_encoder.blocks.0.0.weight
 (8, 1, 3, 3)" fillcolor=lightblue]
	2808858984384 -> 2808908109360
	2808908109360 [label=AccumulateGrad]
	2808908109312 -> 2808908109168
	2808858984304 [label="depth_encoder.blocks.0.0.bias
 (8)" fillcolor=lightblue]
	2808858984304 -> 2808908109312
	2808908109312 [label=AccumulateGrad]
	2808908109120 -> 2808908109072
	2808858971104 [label="depth_encoder.blocks.0.1.weight
 (8)" fillcolor=lightblue]
	2808858971104 -> 2808908109120
	2808908109120 [label=AccumulateGrad]
	2808908108976 -> 2808908109072
	2808858971024 [label="depth_encoder.blocks.0.1.bias
 (8)" fillcolor=lightblue]
	2808858971024 -> 2808908108976
	2808908108976 [label=AccumulateGrad]
	2808908108832 -> 2808908108688
	2808858970864 [label="depth_encoder.blocks.0.3.weight
 (8, 8, 3, 3)" fillcolor=lightblue]
	2808858970864 -> 2808908108832
	2808908108832 [label=AccumulateGrad]
	2808908108784 -> 2808908108688
	2808858978464 [label="depth_encoder.blocks.0.3.bias
 (8)" fillcolor=lightblue]
	2808858978464 -> 2808908108784
	2808908108784 [label=AccumulateGrad]
	2808908108640 -> 2808908108592
	2808858978384 [label="depth_encoder.blocks.0.4.weight
 (8)" fillcolor=lightblue]
	2808858978384 -> 2808908108640
	2808908108640 [label=AccumulateGrad]
	2808908108400 -> 2808908108592
	2808858971904 [label="depth_encoder.blocks.0.4.bias
 (8)" fillcolor=lightblue]
	2808858971904 -> 2808908108400
	2808908108400 [label=AccumulateGrad]
	2808908108256 -> 2808908108112
	2808858901344 [label="depth_encoder.blocks.1.0.weight
 (16, 8, 3, 3)" fillcolor=lightblue]
	2808858901344 -> 2808908108256
	2808908108256 [label=AccumulateGrad]
	2808908108208 -> 2808908108112
	2808858901504 [label="depth_encoder.blocks.1.0.bias
 (16)" fillcolor=lightblue]
	2808858901504 -> 2808908108208
	2808908108208 [label=AccumulateGrad]
	2808908108064 -> 2808908108016
	2808858901424 [label="depth_encoder.blocks.1.1.weight
 (16)" fillcolor=lightblue]
	2808858901424 -> 2808908108064
	2808908108064 [label=AccumulateGrad]
	2808908107920 -> 2808908108016
	2808858901104 [label="depth_encoder.blocks.1.1.bias
 (16)" fillcolor=lightblue]
	2808858901104 -> 2808908107920
	2808908107920 [label=AccumulateGrad]
	2808908107776 -> 2808908107632
	2808858900624 [label="depth_encoder.blocks.1.3.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	2808858900624 -> 2808908107776
	2808908107776 [label=AccumulateGrad]
	2808908107728 -> 2808908107632
	2808858900784 [label="depth_encoder.blocks.1.3.bias
 (16)" fillcolor=lightblue]
	2808858900784 -> 2808908107728
	2808908107728 [label=AccumulateGrad]
	2808908107584 -> 2808908107536
	2808858900704 [label="depth_encoder.blocks.1.4.weight
 (16)" fillcolor=lightblue]
	2808858900704 -> 2808908107584
	2808908107584 [label=AccumulateGrad]
	2808908107344 -> 2808908107536
	2808858900384 [label="depth_encoder.blocks.1.4.bias
 (16)" fillcolor=lightblue]
	2808858900384 -> 2808908107344
	2808908107344 [label=AccumulateGrad]
	2808908107200 -> 2808908107056
	2808858899664 [label="depth_encoder.blocks.2.0.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	2808858899664 -> 2808908107200
	2808908107200 [label=AccumulateGrad]
	2808908107152 -> 2808908107056
	2808858899824 [label="depth_encoder.blocks.2.0.bias
 (32)" fillcolor=lightblue]
	2808858899824 -> 2808908107152
	2808908107152 [label=AccumulateGrad]
	2808908107008 -> 2808908106960
	2808858899744 [label="depth_encoder.blocks.2.1.weight
 (32)" fillcolor=lightblue]
	2808858899744 -> 2808908107008
	2808908107008 [label=AccumulateGrad]
	2808908106864 -> 2808908106960
	2808858899904 [label="depth_encoder.blocks.2.1.bias
 (32)" fillcolor=lightblue]
	2808858899904 -> 2808908106864
	2808908106864 [label=AccumulateGrad]
	2808908106528 -> 2808908106192
	2808858899184 [label="depth_encoder.blocks.2.3.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	2808858899184 -> 2808908106528
	2808908106528 [label=AccumulateGrad]
	2808908106768 -> 2808908106192
	2808858899344 [label="depth_encoder.blocks.2.3.bias
 (32)" fillcolor=lightblue]
	2808858899344 -> 2808908106768
	2808908106768 [label=AccumulateGrad]
	2808908106672 -> 2808908106288
	2808858899264 [label="depth_encoder.blocks.2.4.weight
 (32)" fillcolor=lightblue]
	2808858899264 -> 2808908106672
	2808908106672 [label=AccumulateGrad]
	2808908105808 -> 2808908106288
	2808858886224 [label="depth_encoder.blocks.2.4.bias
 (32)" fillcolor=lightblue]
	2808858886224 -> 2808908105808
	2808908105808 [label=AccumulateGrad]
	2808908104944 -> 2808908104560
	2808858898784 [label="fusion.conv1.weight
 (8, 64, 1, 1)" fillcolor=lightblue]
	2808858898784 -> 2808908104944
	2808908104944 [label=AccumulateGrad]
	2808908104752 -> 2808908104560
	2808858898944 [label="fusion.conv1.bias
 (8)" fillcolor=lightblue]
	2808858898944 -> 2808908104752
	2808908104752 [label=AccumulateGrad]
	2808908104368 -> 2808907775808
	2808858898544 [label="fusion.conv2.weight
 (32, 8, 1, 1)" fillcolor=lightblue]
	2808858898544 -> 2808908104368
	2808908104368 [label=AccumulateGrad]
	2808908103888 -> 2808907775808
	2808858898704 [label="fusion.conv2.bias
 (32)" fillcolor=lightblue]
	2808858898704 -> 2808908103888
	2808908103888 [label=AccumulateGrad]
	2808907775664 -> 2808907775568
	2808907775376 -> 2808907775232
	2808907775376 [label=CatBackward0]
	2808907775904 -> 2808907775376
	2808908105616 -> 2808907775376
	2808907775184 -> 2808907775040
	2808858898064 [label="decoder.blocks.0.conv.0.weight
 (32, 96, 3, 3)" fillcolor=lightblue]
	2808858898064 -> 2808907775184
	2808907775184 [label=AccumulateGrad]
	2808907775136 -> 2808907775040
	2808858898224 [label="decoder.blocks.0.conv.0.bias
 (32)" fillcolor=lightblue]
	2808858898224 -> 2808907775136
	2808907775136 [label=AccumulateGrad]
	2808907774992 -> 2808907774944
	2808858898144 [label="decoder.blocks.0.conv.1.weight
 (32)" fillcolor=lightblue]
	2808858898144 -> 2808907774992
	2808907774992 [label=AccumulateGrad]
	2808907774848 -> 2808907774944
	2808858897824 [label="decoder.blocks.0.conv.1.bias
 (32)" fillcolor=lightblue]
	2808858897824 -> 2808907774848
	2808907774848 [label=AccumulateGrad]
	2808907774704 -> 2808907774560
	2808858897344 [label="decoder.blocks.0.conv.3.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	2808858897344 -> 2808907774704
	2808907774704 [label=AccumulateGrad]
	2808907774656 -> 2808907774560
	2808858897504 [label="decoder.blocks.0.conv.3.bias
 (32)" fillcolor=lightblue]
	2808858897504 -> 2808907774656
	2808907774656 [label=AccumulateGrad]
	2808907774512 -> 2808907774464
	2808858897424 [label="decoder.blocks.0.conv.4.weight
 (32)" fillcolor=lightblue]
	2808858897424 -> 2808907774512
	2808907774512 [label=AccumulateGrad]
	2808907774272 -> 2808907774464
	2808858896864 [label="decoder.blocks.0.conv.4.bias
 (32)" fillcolor=lightblue]
	2808858896864 -> 2808907774272
	2808907774272 [label=AccumulateGrad]
	2808907774176 -> 2808907774032
	2808907774176 [label=CatBackward0]
	2808908104704 -> 2808907774176
	2808908107440 -> 2808907774176
	2808907773984 -> 2808907773840
	2808858897264 [label="decoder.blocks.1.conv.0.weight
 (16, 64, 3, 3)" fillcolor=lightblue]
	2808858897264 -> 2808907773984
	2808907773984 [label=AccumulateGrad]
	2808907773936 -> 2808907773840
	2808858896624 [label="decoder.blocks.1.conv.0.bias
 (16)" fillcolor=lightblue]
	2808858896624 -> 2808907773936
	2808907773936 [label=AccumulateGrad]
	2808907773792 -> 2808907773744
	2808858896784 [label="decoder.blocks.1.conv.1.weight
 (16)" fillcolor=lightblue]
	2808858896784 -> 2808907773792
	2808907773792 [label=AccumulateGrad]
	2808907773648 -> 2808907773744
	2808858896704 [label="decoder.blocks.1.conv.1.bias
 (16)" fillcolor=lightblue]
	2808858896704 -> 2808907773648
	2808907773648 [label=AccumulateGrad]
	2808907773504 -> 2808907773360
	2808858896224 [label="decoder.blocks.1.conv.3.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	2808858896224 -> 2808907773504
	2808907773504 [label=AccumulateGrad]
	2808907773456 -> 2808907773360
	2808858895904 [label="decoder.blocks.1.conv.3.bias
 (16)" fillcolor=lightblue]
	2808858895904 -> 2808907773456
	2808907773456 [label=AccumulateGrad]
	2808907773312 -> 2808907773264
	2808858896064 [label="decoder.blocks.1.conv.4.weight
 (16)" fillcolor=lightblue]
	2808858896064 -> 2808907773312
	2808907773312 [label=AccumulateGrad]
	2808907773120 -> 2808907773264
	2808858895984 [label="decoder.blocks.1.conv.4.bias
 (16)" fillcolor=lightblue]
	2808858895984 -> 2808907773120
	2808907773120 [label=AccumulateGrad]
	2808907773024 -> 2808907772880
	2808907773024 [label=CatBackward0]
	2808908105760 -> 2808907773024
	2808908108496 -> 2808907773024
	2808907772832 -> 2808907772688
	2808858895024 [label="decoder.blocks.2.conv.0.weight
 (8, 32, 3, 3)" fillcolor=lightblue]
	2808858895024 -> 2808907772832
	2808907772832 [label=AccumulateGrad]
	2808907772784 -> 2808907772688
	2808858895184 [label="decoder.blocks.2.conv.0.bias
 (8)" fillcolor=lightblue]
	2808858895184 -> 2808907772784
	2808907772784 [label=AccumulateGrad]
	2808907772640 -> 2808907772592
	2808858895104 [label="decoder.blocks.2.conv.1.weight
 (8)" fillcolor=lightblue]
	2808858895104 -> 2808907772640
	2808907772640 [label=AccumulateGrad]
	2808907772496 -> 2808907772592
	2808858894784 [label="decoder.blocks.2.conv.1.bias
 (8)" fillcolor=lightblue]
	2808858894784 -> 2808907772496
	2808907772496 [label=AccumulateGrad]
	2808907772352 -> 2808907772208
	2808858894304 [label="decoder.blocks.2.conv.3.weight
 (8, 8, 3, 3)" fillcolor=lightblue]
	2808858894304 -> 2808907772352
	2808907772352 [label=AccumulateGrad]
	2808907772304 -> 2808907772208
	2808858894464 [label="decoder.blocks.2.conv.3.bias
 (8)" fillcolor=lightblue]
	2808858894464 -> 2808907772304
	2808907772304 [label=AccumulateGrad]
	2808907772256 -> 2808907771824
	2808858894384 [label="decoder.blocks.2.conv.4.weight
 (8)" fillcolor=lightblue]
	2808858894384 -> 2808907772256
	2808907772256 [label=AccumulateGrad]
	2808907771872 -> 2808907771824
	2808858895664 [label="decoder.blocks.2.conv.4.bias
 (8)" fillcolor=lightblue]
	2808858895664 -> 2808907771872
	2808907771872 [label=AccumulateGrad]
	2808907771968 -> 2808907772016
	2808907863280 [label="decoder.final_conv.weight
 (3, 8, 1, 1)" fillcolor=lightblue]
	2808907863280 -> 2808907771968
	2808907771968 [label=AccumulateGrad]
	2808907772064 -> 2808907772016
	2808907863360 [label="decoder.final_conv.bias
 (3)" fillcolor=lightblue]
	2808907863360 -> 2808907772064
	2808907772064 [label=AccumulateGrad]
	2808907772016 -> 2808907868160
}
