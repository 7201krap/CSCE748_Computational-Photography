digraph {
	graph [size="80.25,80.25"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2708894231888 [label="
 (1, 3, 240, 320)" fillcolor=darkolivegreen1]
	2708893964160 [label=ConvolutionBackward0]
	2708891288720 -> 2708893964160
	2708891288720 [label=ReluBackward0]
	2708892827504 -> 2708891288720
	2708892827504 [label=NativeBatchNormBackward0]
	2708894151104 -> 2708892827504
	2708894151104 [label=ConvolutionBackward0]
	2708894151296 -> 2708894151104
	2708894151296 [label=ReluBackward0]
	2708894151488 -> 2708894151296
	2708894151488 [label=NativeBatchNormBackward0]
	2708894151584 -> 2708894151488
	2708894151584 [label=ConvolutionBackward0]
	2708894151776 -> 2708894151584
	2708894151776 [label=CatBackward0]
	2708893823520 -> 2708894151776
	2708893823520 [label=UpsampleBilinear2DBackward0]
	2708894152064 -> 2708893823520
	2708894152064 [label=ReluBackward0]
	2708894152160 -> 2708894152064
	2708894152160 [label=NativeBatchNormBackward0]
	2708894152256 -> 2708894152160
	2708894152256 [label=ConvolutionBackward0]
	2708894152448 -> 2708894152256
	2708894152448 [label=ReluBackward0]
	2708894152640 -> 2708894152448
	2708894152640 [label=NativeBatchNormBackward0]
	2708894152736 -> 2708894152640
	2708894152736 [label=ConvolutionBackward0]
	2708894152928 -> 2708894152736
	2708894152928 [label=CatBackward0]
	2708894153120 -> 2708894152928
	2708894153120 [label=UpsampleBilinear2DBackward0]
	2708894153264 -> 2708894153120
	2708894153264 [label=ReluBackward0]
	2708894153360 -> 2708894153264
	2708894153360 [label=NativeBatchNormBackward0]
	2708894153456 -> 2708894153360
	2708894153456 [label=ConvolutionBackward0]
	2708894153648 -> 2708894153456
	2708894153648 [label=ReluBackward0]
	2708894153840 -> 2708894153648
	2708894153840 [label=NativeBatchNormBackward0]
	2708894153936 -> 2708894153840
	2708894153936 [label=ConvolutionBackward0]
	2708894154128 -> 2708894153936
	2708894154128 [label=CatBackward0]
	2708894154320 -> 2708894154128
	2708894154320 [label=UpsampleBilinear2DBackward0]
	2708894154464 -> 2708894154320
	2708894154464 [label=ViewBackward0]
	2708894154560 -> 2708894154464
	2708894154560 [label=PermuteBackward0]
	2708894154656 -> 2708894154560
	2708894154656 [label=TransposeBackward0]
	2708894154704 -> 2708894154656
	2708894154704 [label=ViewBackward0]
	2708894466208 -> 2708894154704
	2708894466208 [label=AddmmBackward0]
	2708894466304 -> 2708894466208
	2708844319024 [label="attention.mha.out_proj.bias
 (64)" fillcolor=lightblue]
	2708844319024 -> 2708894466304
	2708894466304 [label=AccumulateGrad]
	2708894466256 -> 2708894466208
	2708894466256 [label=ViewBackward0]
	2708894466448 -> 2708894466256
	2708894466448 [label=CloneBackward0]
	2708894466592 -> 2708894466448
	2708894466592 [label=TransposeBackward0]
	2708894466688 -> 2708894466592
	2708894466688 [label=BmmBackward0]
	2708894466784 -> 2708894466688
	2708894466784 [label=SoftmaxBackward0]
	2708894466928 -> 2708894466784
	2708894466928 [label=BmmBackward0]
	2708894467024 -> 2708894466928
	2708894467024 [label=DivBackward0]
	2708894467168 -> 2708894467024
	2708894467168 [label=TransposeBackward0]
	2708894467264 -> 2708894467168
	2708894467264 [label=ViewBackward0]
	2708894467360 -> 2708894467264
	2708894467360 [label=SelectBackward0]
	2708894467456 -> 2708894467360
	2708894467456 [label=CloneBackward0]
	2708894467552 -> 2708894467456
	2708894467552 [label=SqueezeBackward1]
	2708894467648 -> 2708894467552
	2708894467648 [label=TransposeBackward0]
	2708894467744 -> 2708894467648
	2708894467744 [label=UnsqueezeBackward0]
	2708894467792 -> 2708894467744
	2708894467792 [label=ViewBackward0]
	2708894467936 -> 2708894467792
	2708894467936 [label=AddBackward0]
	2708894468080 -> 2708894467936
	2708894468080 [label=UnsafeViewBackward0]
	2708894468320 -> 2708894468080
	2708894468320 [label=MmBackward0]
	2708894468368 -> 2708894468320
	2708894468368 [label=ReshapeAliasBackward0]
	2708894468608 -> 2708894468368
	2708894468608 [label=TransposeBackward0]
	2708894468656 -> 2708894468608
	2708894468656 [label=PermuteBackward0]
	2708894468800 -> 2708894468656
	2708894468800 [label=ViewBackward0]
	2708894468944 -> 2708894468800
	2708894468944 [label=CatBackward0]
	2708894469088 -> 2708894468944
	2708894469088 [label=MaxPool2DWithIndicesBackward0]
	2708894469328 -> 2708894469088
	2708894469328 [label=ReluBackward0]
	2708894469376 -> 2708894469328
	2708894469376 [label=NativeBatchNormBackward0]
	2708894469520 -> 2708894469376
	2708894469520 [label=ConvolutionBackward0]
	2708894469808 -> 2708894469520
	2708894469808 [label=ReluBackward0]
	2708894470000 -> 2708894469808
	2708894470000 [label=NativeBatchNormBackward0]
	2708894470048 -> 2708894470000
	2708894470048 [label=ConvolutionBackward0]
	2708894470336 -> 2708894470048
	2708894470336 [label=MaxPool2DWithIndicesBackward0]
	2708894470528 -> 2708894470336
	2708894470528 [label=ReluBackward0]
	2708894470576 -> 2708894470528
	2708894470576 [label=NativeBatchNormBackward0]
	2708894470720 -> 2708894470576
	2708894470720 [label=ConvolutionBackward0]
	2708894471008 -> 2708894470720
	2708894471008 [label=ReluBackward0]
	2708894471200 -> 2708894471008
	2708894471200 [label=NativeBatchNormBackward0]
	2708894471248 -> 2708894471200
	2708894471248 [label=ConvolutionBackward0]
	2708894471536 -> 2708894471248
	2708894471536 [label=MaxPool2DWithIndicesBackward0]
	2708894471728 -> 2708894471536
	2708894471728 [label=ReluBackward0]
	2708894471776 -> 2708894471728
	2708894471776 [label=NativeBatchNormBackward0]
	2708894471920 -> 2708894471776
	2708894471920 [label=ConvolutionBackward0]
	2708894472208 -> 2708894471920
	2708894472208 [label=ReluBackward0]
	2708894472400 -> 2708894472208
	2708894472400 [label=NativeBatchNormBackward0]
	2708894472448 -> 2708894472400
	2708894472448 [label=ConvolutionBackward0]
	2708894472736 -> 2708894472448
	2708844294496 [label="rgb_encoder.blocks.0.0.weight
 (8, 3, 3, 3)" fillcolor=lightblue]
	2708844294496 -> 2708894472736
	2708894472736 [label=AccumulateGrad]
	2708894472688 -> 2708894472448
	2708844294256 [label="rgb_encoder.blocks.0.0.bias
 (8)" fillcolor=lightblue]
	2708844294256 -> 2708894472688
	2708894472688 [label=AccumulateGrad]
	2708894472304 -> 2708894472400
	2708844291616 [label="rgb_encoder.blocks.0.1.weight
 (8)" fillcolor=lightblue]
	2708844291616 -> 2708894472304
	2708894472304 [label=AccumulateGrad]
	2708894472544 -> 2708894472400
	2708844291456 [label="rgb_encoder.blocks.0.1.bias
 (8)" fillcolor=lightblue]
	2708844291456 -> 2708894472544
	2708894472544 [label=AccumulateGrad]
	2708894472160 -> 2708894471920
	2708844231600 [label="rgb_encoder.blocks.0.3.weight
 (8, 8, 3, 3)" fillcolor=lightblue]
	2708844231600 -> 2708894472160
	2708894472160 [label=AccumulateGrad]
	2708894472112 -> 2708894471920
	2708844231760 [label="rgb_encoder.blocks.0.3.bias
 (8)" fillcolor=lightblue]
	2708844231760 -> 2708894472112
	2708894472112 [label=AccumulateGrad]
	2708894471872 -> 2708894471776
	2708844231680 [label="rgb_encoder.blocks.0.4.weight
 (8)" fillcolor=lightblue]
	2708844231680 -> 2708894471872
	2708894471872 [label=AccumulateGrad]
	2708894472016 -> 2708894471776
	2708844231360 [label="rgb_encoder.blocks.0.4.bias
 (8)" fillcolor=lightblue]
	2708844231360 -> 2708894472016
	2708894472016 [label=AccumulateGrad]
	2708894471488 -> 2708894471248
	2708844230800 [label="rgb_encoder.blocks.1.0.weight
 (16, 8, 3, 3)" fillcolor=lightblue]
	2708844230800 -> 2708894471488
	2708894471488 [label=AccumulateGrad]
	2708894471440 -> 2708894471248
	2708844230720 [label="rgb_encoder.blocks.1.0.bias
 (16)" fillcolor=lightblue]
	2708844230720 -> 2708894471440
	2708894471440 [label=AccumulateGrad]
	2708894471104 -> 2708894471200
	2708844230400 [label="rgb_encoder.blocks.1.1.weight
 (16)" fillcolor=lightblue]
	2708844230400 -> 2708894471104
	2708894471104 [label=AccumulateGrad]
	2708894471344 -> 2708894471200
	2708844230560 [label="rgb_encoder.blocks.1.1.bias
 (16)" fillcolor=lightblue]
	2708844230560 -> 2708894471344
	2708894471344 [label=AccumulateGrad]
	2708894470960 -> 2708894470720
	2708844230320 [label="rgb_encoder.blocks.1.3.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	2708844230320 -> 2708894470960
	2708894470960 [label=AccumulateGrad]
	2708894470912 -> 2708894470720
	2708844230240 [label="rgb_encoder.blocks.1.3.bias
 (16)" fillcolor=lightblue]
	2708844230240 -> 2708894470912
	2708894470912 [label=AccumulateGrad]
	2708894470672 -> 2708894470576
	2708844229680 [label="rgb_encoder.blocks.1.4.weight
 (16)" fillcolor=lightblue]
	2708844229680 -> 2708894470672
	2708894470672 [label=AccumulateGrad]
	2708894470816 -> 2708894470576
	2708844229840 [label="rgb_encoder.blocks.1.4.bias
 (16)" fillcolor=lightblue]
	2708844229840 -> 2708894470816
	2708894470816 [label=AccumulateGrad]
	2708894470288 -> 2708894470048
	2708844216400 [label="rgb_encoder.blocks.2.0.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	2708844216400 -> 2708894470288
	2708894470288 [label=AccumulateGrad]
	2708894470240 -> 2708894470048
	2708844229280 [label="rgb_encoder.blocks.2.0.bias
 (32)" fillcolor=lightblue]
	2708844229280 -> 2708894470240
	2708894470240 [label=AccumulateGrad]
	2708894469904 -> 2708894470000
	2708844229360 [label="rgb_encoder.blocks.2.1.weight
 (32)" fillcolor=lightblue]
	2708844229360 -> 2708894469904
	2708894469904 [label=AccumulateGrad]
	2708894470144 -> 2708894470000
	2708844221920 [label="rgb_encoder.blocks.2.1.bias
 (32)" fillcolor=lightblue]
	2708844221920 -> 2708894470144
	2708894470144 [label=AccumulateGrad]
	2708894469760 -> 2708894469520
	2708844229120 [label="rgb_encoder.blocks.2.3.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	2708844229120 -> 2708894469760
	2708894469760 [label=AccumulateGrad]
	2708894469712 -> 2708894469520
	2708844228800 [label="rgb_encoder.blocks.2.3.bias
 (32)" fillcolor=lightblue]
	2708844228800 -> 2708894469712
	2708894469712 [label=AccumulateGrad]
	2708894469472 -> 2708894469376
	2708844228960 [label="rgb_encoder.blocks.2.4.weight
 (32)" fillcolor=lightblue]
	2708844228960 -> 2708894469472
	2708894469472 [label=AccumulateGrad]
	2708894469616 -> 2708894469376
	2708844228880 [label="rgb_encoder.blocks.2.4.bias
 (32)" fillcolor=lightblue]
	2708844228880 -> 2708894469616
	2708894469616 [label=AccumulateGrad]
	2708894469040 -> 2708894468944
	2708894469040 [label=MaxPool2DWithIndicesBackward0]
	2708894469664 -> 2708894469040
	2708894469664 [label=ReluBackward0]
	2708894469952 -> 2708894469664
	2708894469952 [label=NativeBatchNormBackward0]
	2708894470432 -> 2708894469952
	2708894470432 [label=ConvolutionBackward0]
	2708894471392 -> 2708894470432
	2708894471392 [label=ReluBackward0]
	2708894472064 -> 2708894471392
	2708894472064 [label=NativeBatchNormBackward0]
	2708894471680 -> 2708894472064
	2708894471680 [label=ConvolutionBackward0]
	2708894472592 -> 2708894471680
	2708894472592 [label=MaxPool2DWithIndicesBackward0]
	2708894472928 -> 2708894472592
	2708894472928 [label=ReluBackward0]
	2708894473024 -> 2708894472928
	2708894473024 [label=NativeBatchNormBackward0]
	2708894473120 -> 2708894473024
	2708894473120 [label=ConvolutionBackward0]
	2708894473312 -> 2708894473120
	2708894473312 [label=ReluBackward0]
	2708894473504 -> 2708894473312
	2708894473504 [label=NativeBatchNormBackward0]
	2708894473600 -> 2708894473504
	2708894473600 [label=ConvolutionBackward0]
	2708894473792 -> 2708894473600
	2708894473792 [label=MaxPool2DWithIndicesBackward0]
	2708894473984 -> 2708894473792
	2708894473984 [label=ReluBackward0]
	2708894474080 -> 2708894473984
	2708894474080 [label=NativeBatchNormBackward0]
	2708894474176 -> 2708894474080
	2708894474176 [label=ConvolutionBackward0]
	2708894474368 -> 2708894474176
	2708894474368 [label=ReluBackward0]
	2708894474560 -> 2708894474368
	2708894474560 [label=NativeBatchNormBackward0]
	2708894474704 -> 2708894474560
	2708894474704 [label=ConvolutionBackward0]
	2708894474848 -> 2708894474704
	2708844228080 [label="depth_encoder.blocks.0.0.weight
 (8, 1, 3, 3)" fillcolor=lightblue]
	2708844228080 -> 2708894474848
	2708894474848 [label=AccumulateGrad]
	2708894474800 -> 2708894474704
	2708844228240 [label="depth_encoder.blocks.0.0.bias
 (8)" fillcolor=lightblue]
	2708844228240 -> 2708894474800
	2708894474800 [label=AccumulateGrad]
	2708894474608 -> 2708894474560
	2708844228160 [label="depth_encoder.blocks.0.1.weight
 (8)" fillcolor=lightblue]
	2708844228160 -> 2708894474608
	2708894474608 [label=AccumulateGrad]
	2708894474464 -> 2708894474560
	2708844227840 [label="depth_encoder.blocks.0.1.bias
 (8)" fillcolor=lightblue]
	2708844227840 -> 2708894474464
	2708894474464 [label=AccumulateGrad]
	2708894474320 -> 2708894474176
	2708844227120 [label="depth_encoder.blocks.0.3.weight
 (8, 8, 3, 3)" fillcolor=lightblue]
	2708844227120 -> 2708894474320
	2708894474320 [label=AccumulateGrad]
	2708894474272 -> 2708894474176
	2708844227280 [label="depth_encoder.blocks.0.3.bias
 (8)" fillcolor=lightblue]
	2708844227280 -> 2708894474272
	2708894474272 [label=AccumulateGrad]
	2708894474128 -> 2708894474080
	2708844227200 [label="depth_encoder.blocks.0.4.weight
 (8)" fillcolor=lightblue]
	2708844227200 -> 2708894474128
	2708894474128 [label=AccumulateGrad]
	2708894473888 -> 2708894474080
	2708844227360 [label="depth_encoder.blocks.0.4.bias
 (8)" fillcolor=lightblue]
	2708844227360 -> 2708894473888
	2708894473888 [label=AccumulateGrad]
	2708894473744 -> 2708894473600
	2708844226640 [label="depth_encoder.blocks.1.0.weight
 (16, 8, 3, 3)" fillcolor=lightblue]
	2708844226640 -> 2708894473744
	2708894473744 [label=AccumulateGrad]
	2708894473696 -> 2708894473600
	2708844226800 [label="depth_encoder.blocks.1.0.bias
 (16)" fillcolor=lightblue]
	2708844226800 -> 2708894473696
	2708894473696 [label=AccumulateGrad]
	2708894473552 -> 2708894473504
	2708844226720 [label="depth_encoder.blocks.1.1.weight
 (16)" fillcolor=lightblue]
	2708844226720 -> 2708894473552
	2708894473552 [label=AccumulateGrad]
	2708894473408 -> 2708894473504
	2708844226400 [label="depth_encoder.blocks.1.1.bias
 (16)" fillcolor=lightblue]
	2708844226400 -> 2708894473408
	2708894473408 [label=AccumulateGrad]
	2708894473264 -> 2708894473120
	2708844225680 [label="depth_encoder.blocks.1.3.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	2708844225680 -> 2708894473264
	2708894473264 [label=AccumulateGrad]
	2708894473216 -> 2708894473120
	2708844225840 [label="depth_encoder.blocks.1.3.bias
 (16)" fillcolor=lightblue]
	2708844225840 -> 2708894473216
	2708894473216 [label=AccumulateGrad]
	2708894473072 -> 2708894473024
	2708844225760 [label="depth_encoder.blocks.1.4.weight
 (16)" fillcolor=lightblue]
	2708844225760 -> 2708894473072
	2708894473072 [label=AccumulateGrad]
	2708894472640 -> 2708894473024
	2708844225440 [label="depth_encoder.blocks.1.4.bias
 (16)" fillcolor=lightblue]
	2708844225440 -> 2708894472640
	2708894472640 [label=AccumulateGrad]
	2708894472256 -> 2708894471680
	2708844224960 [label="depth_encoder.blocks.2.0.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	2708844224960 -> 2708894472256
	2708894472256 [label=AccumulateGrad]
	2708894472784 -> 2708894471680
	2708844225120 [label="depth_encoder.blocks.2.0.bias
 (32)" fillcolor=lightblue]
	2708844225120 -> 2708894472784
	2708894472784 [label=AccumulateGrad]
	2708894471584 -> 2708894472064
	2708844225040 [label="depth_encoder.blocks.2.1.weight
 (32)" fillcolor=lightblue]
	2708844225040 -> 2708894471584
	2708894471584 [label=AccumulateGrad]
	2708894471056 -> 2708894472064
	2708844224720 [label="depth_encoder.blocks.2.1.bias
 (32)" fillcolor=lightblue]
	2708844224720 -> 2708894471056
	2708894471056 [label=AccumulateGrad]
	2708894470864 -> 2708894470432
	2708844225920 [label="depth_encoder.blocks.2.3.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	2708844225920 -> 2708894470864
	2708894470864 [label=AccumulateGrad]
	2708894470384 -> 2708894470432
	2708844226080 [label="depth_encoder.blocks.2.3.bias
 (32)" fillcolor=lightblue]
	2708844226080 -> 2708894470384
	2708894470384 [label=AccumulateGrad]
	2708894469856 -> 2708894469952
	2708844226000 [label="depth_encoder.blocks.2.4.weight
 (32)" fillcolor=lightblue]
	2708844226000 -> 2708894469856
	2708894469856 [label=AccumulateGrad]
	2708894469280 -> 2708894469952
	2708844231840 [label="depth_encoder.blocks.2.4.bias
 (32)" fillcolor=lightblue]
	2708844231840 -> 2708894469280
	2708894469280 [label=AccumulateGrad]
	2708894468224 -> 2708894468320
	2708894468224 [label=TBackward0]
	2708894468752 -> 2708894468224
	2708844319424 [label="attention.mha.in_proj_weight
 (192, 64)" fillcolor=lightblue]
	2708844319424 -> 2708894468752
	2708894468752 [label=AccumulateGrad]
	2708894468032 -> 2708894467936
	2708844319344 [label="attention.mha.in_proj_bias
 (192)" fillcolor=lightblue]
	2708844319344 -> 2708894468032
	2708894468032 [label=AccumulateGrad]
	2708894466976 -> 2708894466928
	2708894466976 [label=TransposeBackward0]
	2708891204816 -> 2708894466976
	2708891204816 [label=TransposeBackward0]
	2708894467408 -> 2708891204816
	2708894467408 [label=ViewBackward0]
	2708894467600 -> 2708894467408
	2708894467600 [label=SelectBackward0]
	2708894467456 -> 2708894467600
	2708894466736 -> 2708894466688
	2708894466736 [label=TransposeBackward0]
	2708894467216 -> 2708894466736
	2708894467216 [label=ViewBackward0]
	2708894467504 -> 2708894467216
	2708894467504 [label=SelectBackward0]
	2708894467456 -> 2708894467504
	2708894466112 -> 2708894466208
	2708894466112 [label=TBackward0]
	2708894466640 -> 2708894466112
	2708844319104 [label="attention.mha.out_proj.weight
 (64, 64)" fillcolor=lightblue]
	2708844319104 -> 2708894466640
	2708894466640 [label=AccumulateGrad]
	2708894154272 -> 2708894154128
	2708894154272 [label=CatBackward0]
	2708894469328 -> 2708894154272
	2708894469664 -> 2708894154272
	2708894154080 -> 2708894153936
	2708844318304 [label="decoder.blocks.0.conv.0.weight
 (32, 128, 3, 3)" fillcolor=lightblue]
	2708844318304 -> 2708894154080
	2708894154080 [label=AccumulateGrad]
	2708894154032 -> 2708894153936
	2708844318224 [label="decoder.blocks.0.conv.0.bias
 (32)" fillcolor=lightblue]
	2708844318224 -> 2708894154032
	2708894154032 [label=AccumulateGrad]
	2708894153888 -> 2708894153840
	2708844318144 [label="decoder.blocks.0.conv.1.weight
 (32)" fillcolor=lightblue]
	2708844318144 -> 2708894153888
	2708894153888 [label=AccumulateGrad]
	2708894153744 -> 2708894153840
	2708844318064 [label="decoder.blocks.0.conv.1.bias
 (32)" fillcolor=lightblue]
	2708844318064 -> 2708894153744
	2708894153744 [label=AccumulateGrad]
	2708894153600 -> 2708894153456
	2708844317584 [label="decoder.blocks.0.conv.3.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	2708844317584 -> 2708894153600
	2708894153600 [label=AccumulateGrad]
	2708894153552 -> 2708894153456
	2708844317504 [label="decoder.blocks.0.conv.3.bias
 (32)" fillcolor=lightblue]
	2708844317504 -> 2708894153552
	2708894153552 [label=AccumulateGrad]
	2708894153408 -> 2708894153360
	2708844317424 [label="decoder.blocks.0.conv.4.weight
 (32)" fillcolor=lightblue]
	2708844317424 -> 2708894153408
	2708894153408 [label=AccumulateGrad]
	2708894153168 -> 2708894153360
	2708844317344 [label="decoder.blocks.0.conv.4.bias
 (32)" fillcolor=lightblue]
	2708844317344 -> 2708894153168
	2708894153168 [label=AccumulateGrad]
	2708894153072 -> 2708894152928
	2708894153072 [label=CatBackward0]
	2708894470528 -> 2708894153072
	2708894472928 -> 2708894153072
	2708894152880 -> 2708894152736
	2708844316864 [label="decoder.blocks.1.conv.0.weight
 (16, 64, 3, 3)" fillcolor=lightblue]
	2708844316864 -> 2708894152880
	2708894152880 [label=AccumulateGrad]
	2708894152832 -> 2708894152736
	2708844316784 [label="decoder.blocks.1.conv.0.bias
 (16)" fillcolor=lightblue]
	2708844316784 -> 2708894152832
	2708894152832 [label=AccumulateGrad]
	2708894152688 -> 2708894152640
	2708844316704 [label="decoder.blocks.1.conv.1.weight
 (16)" fillcolor=lightblue]
	2708844316704 -> 2708894152688
	2708894152688 [label=AccumulateGrad]
	2708894152544 -> 2708894152640
	2708844316624 [label="decoder.blocks.1.conv.1.bias
 (16)" fillcolor=lightblue]
	2708844316624 -> 2708894152544
	2708894152544 [label=AccumulateGrad]
	2708894152400 -> 2708894152256
	2708844316304 [label="decoder.blocks.1.conv.3.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	2708844316304 -> 2708894152400
	2708894152400 [label=AccumulateGrad]
	2708894152352 -> 2708894152256
	2708844316064 [label="decoder.blocks.1.conv.3.bias
 (16)" fillcolor=lightblue]
	2708844316064 -> 2708894152352
	2708894152352 [label=AccumulateGrad]
	2708894152208 -> 2708894152160
	2708844315984 [label="decoder.blocks.1.conv.4.weight
 (16)" fillcolor=lightblue]
	2708844315984 -> 2708894152208
	2708894152208 [label=AccumulateGrad]
	2708894151872 -> 2708894152160
	2708844315904 [label="decoder.blocks.1.conv.4.bias
 (16)" fillcolor=lightblue]
	2708844315904 -> 2708894151872
	2708894151872 [label=AccumulateGrad]
	2708894151968 -> 2708894151776
	2708894151968 [label=CatBackward0]
	2708894471728 -> 2708894151968
	2708894473984 -> 2708894151968
	2708894151728 -> 2708894151584
	2708844315264 [label="decoder.blocks.2.conv.0.weight
 (8, 32, 3, 3)" fillcolor=lightblue]
	2708844315264 -> 2708894151728
	2708894151728 [label=AccumulateGrad]
	2708894151680 -> 2708894151584
	2708844315184 [label="decoder.blocks.2.conv.0.bias
 (8)" fillcolor=lightblue]
	2708844315184 -> 2708894151680
	2708894151680 [label=AccumulateGrad]
	2708894151536 -> 2708894151488
	2708844315104 [label="decoder.blocks.2.conv.1.weight
 (8)" fillcolor=lightblue]
	2708844315104 -> 2708894151536
	2708894151536 [label=AccumulateGrad]
	2708894151392 -> 2708894151488
	2708844315024 [label="decoder.blocks.2.conv.1.bias
 (8)" fillcolor=lightblue]
	2708844315024 -> 2708894151392
	2708894151392 [label=AccumulateGrad]
	2708894151248 -> 2708894151104
	2708844315344 [label="decoder.blocks.2.conv.3.weight
 (8, 8, 3, 3)" fillcolor=lightblue]
	2708844315344 -> 2708894151248
	2708894151248 [label=AccumulateGrad]
	2708894151200 -> 2708894151104
	2708844319904 [label="decoder.blocks.2.conv.3.bias
 (8)" fillcolor=lightblue]
	2708844319904 -> 2708894151200
	2708894151200 [label=AccumulateGrad]
	2708894151152 -> 2708892827504
	2708844319824 [label="decoder.blocks.2.conv.4.weight
 (8)" fillcolor=lightblue]
	2708844319824 -> 2708894151152
	2708894151152 [label=AccumulateGrad]
	2708894150912 -> 2708892827504
	2708894225888 [label="decoder.blocks.2.conv.4.bias
 (8)" fillcolor=lightblue]
	2708894225888 -> 2708894150912
	2708894150912 [label=AccumulateGrad]
	2708894150960 -> 2708893964160
	2708894226368 [label="decoder.final_conv.weight
 (3, 8, 1, 1)" fillcolor=lightblue]
	2708894226368 -> 2708894150960
	2708894150960 [label=AccumulateGrad]
	2708894150864 -> 2708893964160
	2708894226448 [label="decoder.final_conv.bias
 (3)" fillcolor=lightblue]
	2708894226448 -> 2708894150864
	2708894150864 [label=AccumulateGrad]
	2708893964160 -> 2708894231888
}
